import datetime
import os
import sys
import argparse
import glob
import json
import logging
from pathlib import Path
import re
import requests
from typing import List, Dict, Any, Optional, Union
from google import genai

# Configuration
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
MODEL_NAME = "Gemini"
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent"
DEFAULT_OUTPUT_DIR = "generated_tests"
TEST_FILE_PREFIX = "test_"

PREAMBLE = lambda   model_name=MODEL_NAME, \
                    date_str=datetime.datetime.now().strftime("%Y-%m-%d"), \
                    mlc_open="\"\"\"", \
                    mlc_close="\"\"\"" \
: f"""{mlc_open}
This file was generated by {model_name} on {date_str}.
The author of test-for-me is not responsible for the quality or correctness of the generated tests.
Please review and modify the generated tests as needed.
{mlc_close}
"""

client = genai.Client(api_key=GEMINI_API_KEY)

def prompt_gemini(prompt: str) -> str:
    try:
        response = client.models.generate_content(
            model="gemini-2.0-flash", contents=prompt
        )
        print(response)
        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {e}")
        return ""

class TestGenerator:
    """Class to handle unit test generation using Gemini API."""

    def __init__(
        self,
        api_key: str,
        verbose: bool = False,
        dry_run: bool = False
    ):
        """Initialize the TestGenerator.

        Args:
            api_key: Gemini API key
            verbose: Whether to print verbose output
            dry_run: Whether to perform a dry run (no API calls or file writing)
        """
        self.api_key = api_key
        self.dry_run = dry_run

        # Set up logging
        self.logger = logging.getLogger("gemini_test_gen")
        log_level = logging.DEBUG if verbose else logging.INFO
        logging.basicConfig(
            level=log_level,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )

    def validate_python_file(self, file_path: str) -> bool:
        """Check if a file is a valid Python file.

        Args:
            file_path: Path to the file

        Returns:
            bool: True if valid Python file, False otherwise
        """
        if not os.path.isfile(file_path):
            self.logger.warning(f"Not a file: {file_path}")
            return False

        if not file_path.endswith('.py'):
            self.logger.warning(f"Not a Python file: {file_path}")
            return False

        # Check if file is already a test file
        if os.path.basename(file_path).startswith(TEST_FILE_PREFIX):
            self.logger.info(f"Skipping test file: {file_path}")
            return False

        return True

    def find_python_files(
        self,
        path: str,
        recursive: bool = False,
        ignore_patterns: Optional[List[re.Pattern]] = None
    ) -> List[str]:
        """Find Python files in a directory.

        Args:
            path: Path to the directory or file
            recursive: Whether to search recursively
            ignore_patterns: List of regex patterns to ignore

        Returns:
            List of Python files
        """
        ignore_patterns = ignore_patterns or []
        python_files = []

        # If path is a directory, find all Python files
        if os.path.isdir(path):
            search_pattern = os.path.join(path, "**/*.py" if recursive else "*.py")
            all_files = glob.glob(search_pattern, recursive=recursive)

            # Filter out test files and ignored patterns
            for file_path in all_files:
                # Skip if file matches any ignore pattern
                if any(re.match(pattern, file_path) for pattern in ignore_patterns):
                    self.logger.debug(f"Ignoring file (matched pattern): {file_path}")
                    continue

                # Skip test files
                if os.path.basename(file_path).startswith(TEST_FILE_PREFIX):
                    self.logger.debug(f"Skipping test file: {file_path}")
                    continue

                python_files.append(file_path)
        # If path is a file, verify it's a Python file
        elif self.validate_python_file(path):
            python_files.append(path)

        return python_files

    def read_python_file(self, file_path: str) -> str:
        """Read the content of a Python file.

        Args:
            file_path: Path to the Python file

        Returns:
            Content of the file
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return content
        except Exception as e:
            self.logger.error(f"Error reading file {file_path}: {e}")
            return ""

    def generate_test_prompt(self, file_content: str, file_path: str) -> str:
        """Generate a prompt for the Gemini API.

        Args:
            file_content: Content of the Python file
            file_path: Path to the Python file

        Returns:
            Prompt for the Gemini API
        """
        return f"""
You are a Python test engineer. Generate comprehensive unit tests for the following Python code.

File path: {file_path}

PYTHON CODE:
```python
{file_content}
```

Requirements:
1. Use pytest framework
2. Create isolated tests with proper assertions
3. Include docstrings for each test function
4. Use mocks and patches where appropriate for external dependencies
5. Cover edge cases and error conditions
6. Structure the tests following best practices
7. Return only the test code without explanations

GENERATED TESTS:
"""

    def get_output_file_path(
        self,
        python_file: str,
        output_dir: str,
        mirror: bool = False
    ) -> str:
        """Get the output file path for a generated test.

        Args:
            python_file: Path to the Python file
            output_dir: Output directory
            mirror: Whether to mirror the output directory structure
                    Default is False to maintain compatibility with existing tests

        Returns:
            Output file path
        """
        file_name = os.path.basename(python_file)
        test_file_name = f"{TEST_FILE_PREFIX}{file_name}"

        if mirror:
            # Put all test files directly in the output directory
            return os.path.join(output_dir, test_file_name)
        else:
            # Maintain directory structure relative to current directory
            rel_path = os.path.relpath(python_file)
            rel_dir = os.path.dirname(rel_path)
            output_path = os.path.join(output_dir, rel_dir)

            # Create the directory if it doesn't exist
            os.makedirs(output_path, exist_ok=True)

            return os.path.join(output_path, test_file_name)

    def write_test_file(
        self,
        output_path: str,
        test_content: str,
        force: bool = False
    ) -> bool:
        """Write the generated test content to a file.

        Args:
            output_path: Path to write the test file
            test_content: Generated test content
            force: Whether to overwrite existing files

        Returns:
            bool: True if file was written, False otherwise
        """
        if self.dry_run:
            self.logger.info(f"Dry run mode - would write to: {output_path}")
            return True

        # Check if file already exists
        if os.path.exists(output_path) and not force:
            self.logger.warning(f"File already exists (use --force to overwrite): {output_path}")
            return False

        # Create directory if it doesn't exist
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(test_content)
            self.logger.info(f"Test file written to: {output_path}")
            return True
        except Exception as e:
            self.logger.error(f"Error writing test file {output_path}: {e}")
            return False

    def generate_tests_for_file(
        self,
        file_path: str,
        output_dir: str,
        mirror: bool = False,
        force: bool = False
    ) -> bool:
        """Generate unit tests for a single Python file.

        Args:
            file_path: Path to the Python file
            output_dir: Output directory
            mirror: Whether to mirror the output directory structure
            force: Whether to overwrite existing files

        Returns:
            bool: True if successful, False otherwise
        """
        self.logger.info(f"Generating tests for: {file_path}")

        # Read the file content
        file_content = self.read_python_file(file_path)
        if not file_content:
            return False

        # Generate the prompt
        prompt = self.generate_test_prompt(file_content, file_path)

        # Call the Gemini API
        test_content = prompt_gemini(prompt)
        if not test_content:
            self.logger.error(f"Failed to generate tests for: {file_path}")
            return False

        # Get the output file path
        output_path = self.get_output_file_path(file_path, output_dir, mirror=mirror)
        cleaned = clean_test_content(test_content)
        final_output = PREAMBLE(MODEL_NAME, datetime.datetime.now().strftime("%Y-%m-%d")) + cleaned
        # Write the test file
        return self.write_test_file(output_path, final_output, force)

def clean_test_content(test_content: str) -> str:
    """Clean up the generated test content.

    Args:
        test_content: Generated test content

    Returns:
        Cleaned test content
    """
    out = []
    temp = []
    OPEN_SCOPE = CLOSE_SCOPE = "```"
    already_opened = False

    for line in test_content.strip().splitlines():
        if line.startswith(OPEN_SCOPE) and not already_opened:
            already_opened = True
            temp = []
        elif line.startswith(CLOSE_SCOPE) and already_opened:
            already_opened = False
            out.extend(temp)
        elif already_opened:
            temp.append(line)

    return "\n".join(out)

def parse_ignore_patterns(ignore_str: Optional[str]) -> List[re.Pattern]:
    """Parse the ignore patterns string into a list of patterns.

    Args:
        ignore_str: Comma-separated string of glob patterns

    Returns:
        List of compiled regex patterns
    """
    if not ignore_str:
        return []

    patterns = []
    for pattern in ignore_str.split(','):
        pattern = pattern.strip()
        if pattern:
            # Convert glob pattern to regex
            regex_pattern = re.compile(glob.fnmatch.translate(pattern))
            patterns.append(regex_pattern)

    return patterns


def main(args):
    """Main function to generate unit tests.

    Args:
        args: Command line arguments
    """
    # Validate API key
    if not GEMINI_API_KEY:
        print("Error: Gemini API key not found. Set the GEMINI_API_KEY environment "
              "variable or use the --api_key argument.")
        sys.exit(1)

    # Set output directory
    output_dir = args.output or DEFAULT_OUTPUT_DIR

    # Parse ignore patterns
    ignore_patterns = parse_ignore_patterns(args.ignore)

    # Initialize the test generator
    test_generator = TestGenerator(
        api_key=GEMINI_API_KEY,
        verbose=args.verbose,
        dry_run=args.dry_run
    )

    # Find Python files
    python_files = test_generator.find_python_files(
        args.path,
        recursive=args.recursive,
        ignore_patterns=ignore_patterns
    )

    if not python_files:
        print(f"No Python files found at: {args.path}")
        sys.exit(1)

    print(f"Found {len(python_files)} Python file(s) to process")

    # Generate tests for each file
    success_count = 0
    for file_path in python_files:
        if test_generator.generate_tests_for_file(
            file_path,
            output_dir,
            mirror=args.mirror,
            force=args.force
        ):
            success_count += 1

    # Print summary
    print(f"\nSummary: Generated tests for {success_count}/{len(python_files)} files")
    if not args.dry_run and success_count > 0:
        print(f"Output directory: {os.path.abspath(output_dir)}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate unit tests for Python code using Gemini API")

    parser.add_argument("--api_key", type=str, help="API Key for Gemini (can also be set via GEMINI_API_KEY environment variable)")
    parser.add_argument("path", type=str, help="Path to the Python file or directory to generate unit tests for")
    parser.add_argument("-r", "--recursive", action="store_true", help="Recursively generate unit tests for all files in a directory")
    parser.add_argument("-o", "--output", type=str, help=f"Output directory for generated unit tests (default: {DEFAULT_OUTPUT_DIR})")
    parser.add_argument("--mirror", action="store_false", help="Mirror the output directory structure")
    parser.add_argument("--verbose", action="store_true", help="Print verbose output")
    parser.add_argument("--dry_run", action="store_true", help="Dry run (no API calls or file writing)")
    parser.add_argument("-f", "--force", action="store_true", help="Force overwrite of existing unit tests")
    parser.add_argument("--ignore", type=str, help="Comma-separated list of glob patterns to ignore (e.g. 'setup.py,*_pb2.py')")
    parser.add_argument("--no-preamble", action="store_true", help="Do not include the test generation preamble")

    args = parser.parse_args()

    if args.api_key:
        GEMINI_API_KEY = args.api_key
        client = genai.Client(api_key=GEMINI_API_KEY)

    main(args)
